#!/usr/bin/env python3
"""
Advanced Evaluation with Business Metrics and Ranking Optimization
Integrates ranking_metrics_evaluation.py and business_logic_system.py
"""

import torch
import numpy as np
import pandas as pd
import pickle
import json
from pathlib import Path
import time
import argparse
from typing import Dict, List, Tuple, Any
import matplotlib.pyplot as plt
import seaborn as sns

# Import our advanced components
from src.evaluation.ranking_metrics_evaluation import RecommenderMetrics
from src.business.business_logic_system import BusinessRulesEngine, UserProfile
from src.evaluation.evaluate_model import ModelEvaluator, HybridVAE

class AdvancedModelEvaluator(ModelEvaluator):
    """Enhanced model evaluator with business metrics and ranking optimization"""
    
    def __init__(self, model_path: str, data_dir: str = "data/processed"):
        super().__init__(model_path, data_dir)
        self.ranking_metrics = RecommenderMetrics()
        self.business_engine = None
        
    def load_model_and_data(self):
        """Load model, data, and initialize business engine"""
        # Call parent method first to ensure all attributes are set
        super().load_model_and_data()
        
        # Initialize business rules engine
        try:
            if hasattr(self, 'movies_df') and self.movies_df is not None:
                self.business_engine = BusinessRulesEngine(self.movies_df)
                print("‚úÖ Business rules engine initialized")
            else:
                print("‚ö†Ô∏è Movies data not available - business engine not initialized")
        except Exception as e:
            print(f"‚ö†Ô∏è Could not initialize business engine: {e}")
            self.business_engine = None
    
    def predict_ratings(self, user_id: int, movie_ids: List[int]) -> np.ndarray:
        """Predict ratings for user-movie pairs"""
        if not self.model or not self.mappings:
            return np.array([])
        
        try:
            # Map IDs to model indices
            if user_id not in self.mappings['user_to_index']:
                # Handle cold start - use average user embedding
                user_idx = 0  # Could use mean embedding or random
            else:
                user_idx = self.mappings['user_to_index'][user_id]
            
            valid_movie_indices = []
            valid_movie_ids = []
            
            for movie_id in movie_ids:
                if movie_id in self.mappings['movie_to_index']:
                    valid_movie_indices.append(self.mappings['movie_to_index'][movie_id])
                    valid_movie_ids.append(movie_id)
            
            if not valid_movie_indices:
                return np.array([])
            
            # Predict with model
            with torch.no_grad():
                user_tensor = torch.tensor([user_idx] * len(valid_movie_indices), dtype=torch.long, device=self.device)
                movie_tensor = torch.tensor(valid_movie_indices, dtype=torch.long, device=self.device)
                
                predictions, _, _ = self.model(user_tensor, movie_tensor, (0.5, 5.0))
                ratings = predictions.cpu().numpy().flatten()
            
            return ratings
            
        except Exception as e:
            print(f"Error in prediction: {e}")
            # Fallback to random predictions
            return np.random.uniform(2.0, 4.5, len(movie_ids))
    
    def get_top_recommendations(self, user_id: int, n_recommendations: int = 10) -> List[Dict]:
        """Get top N movie recommendations for a user"""
        if not self.model or not self.mappings or not hasattr(self, 'movies_df') or self.movies_df is None:
            return []
        
        try:
            # Get candidate movies (subset for efficiency)
            all_movie_ids = list(self.mappings['movie_to_index'].keys())
            candidate_movies = all_movie_ids[:1000] if len(all_movie_ids) > 1000 else all_movie_ids
            
            # Predict ratings
            predicted_ratings = self.predict_ratings(user_id, candidate_movies)
            
            if len(predicted_ratings) == 0:
                return []
            
            # Get top recommendations
            top_indices = np.argsort(predicted_ratings)[-n_recommendations:][::-1]
            
            recommendations = []
            for idx in top_indices:
                movie_id = candidate_movies[idx]
                rating = predicted_ratings[idx]
                
                # Get movie details
                movie_info = self.movies_df[self.movies_df['movieId'] == movie_id]
                if not movie_info.empty:
                    movie_row = movie_info.iloc[0]
                    
                    recommendations.append({
                        'movie_id': int(movie_id),
                        'title': movie_row.get('title', f'Movie {movie_id}'),
                        'genres': movie_row.get('genres', 'Unknown'),
                        'release_year': movie_row.get('release_year'),
                        'predicted_rating': float(rating)
                    })
            
            return recommendations
            
        except Exception as e:
            print(f"Error generating recommendations: {e}")
            return []
    
    def evaluate_ranking_metrics(self, data: pd.DataFrame, dataset_name: str, 
                                max_samples: int = 2000) -> Dict:
        """Evaluate advanced ranking metrics (mAP, NDCG, MRR)"""
        print(f"\nüéØ Evaluating ranking metrics on {dataset_name} data...")
        
        if data is None or len(data) == 0:
            return {}
        
        # Sample data for evaluation
        if len(data) > max_samples:
            data_sample = data.sample(n=max_samples, random_state=42)
        else:
            data_sample = data
        
        # Group by users to evaluate ranking per user
        user_groups = data_sample.groupby('userId')
        
        # Separate metrics for k=10 specifically
        map_10_scores = []
        ndcg_10_scores = []
        mrr_10_scores = []
        users_evaluated = 0
        
        print(f"   Evaluating {len(user_groups)} users...")
        
        for user_id, user_data in list(user_groups)[:500]:  # Limit to 500 users for better coverage            
            if user_id not in self.mappings['user_to_index']:
                continue
                
            # Get movie IDs and ratings for this user
            movie_ids = user_data['movieId'].values
            true_ratings = user_data['rating'].values
            
            # Need at least 5 ratings for meaningful ranking evaluation
            if len(movie_ids) < 5:
                continue
                
            # Get valid movies (in our mappings)
            valid_mask = np.array([mid in self.mappings['movie_to_index'] for mid in movie_ids])
            if not valid_mask.any() or valid_mask.sum() < 5:
                continue
                
            valid_movie_ids = movie_ids[valid_mask]
            valid_ratings = true_ratings[valid_mask]
            
            # Need at least some highly rated items (4+ stars) for meaningful ranking
            if (valid_ratings >= 4.0).sum() == 0:
                continue
            
            # Get predictions from model
            predicted_scores = self.predict_ratings(user_id, valid_movie_ids.tolist())
            if len(predicted_scores) == 0 or len(predicted_scores) != len(valid_ratings):
                continue
            
            try:
                # Calculate ranking metrics for k=10
                k = 10
                map_k = self.ranking_metrics.mean_average_precision_at_k(valid_ratings, predicted_scores, k)
                mrr_k = self.ranking_metrics.mean_reciprocal_rank_at_k(valid_ratings, predicted_scores, k)
                
                # NDCG using sklearn
                from sklearn.metrics import ndcg_score
                # Convert to binary relevance (4+ stars = relevant)
                binary_relevance = (valid_ratings >= 4.0).astype(int)
                
                if binary_relevance.sum() > 0:  # Only if there are relevant items
                    ndcg_k = ndcg_score([binary_relevance], [predicted_scores], k=k)
                    
                    # Only add if we got valid metrics
                    if not np.isnan(map_k) and not np.isnan(mrr_k) and not np.isnan(ndcg_k):
                        map_10_scores.append(map_k)
                        mrr_10_scores.append(mrr_k)
                        ndcg_10_scores.append(ndcg_k)
                        users_evaluated += 1
                            
            except Exception as e:
                print(f"   Error evaluating user {user_id}: {e}")
                continue
        
        ranking_results = {
            'mAP@10': float(np.mean(map_10_scores)) if map_10_scores else 0.0,
            'NDCG@10': float(np.mean(ndcg_10_scores)) if ndcg_10_scores else 0.0,
            'MRR@10': float(np.mean(mrr_10_scores)) if mrr_10_scores else 0.0,
            'users_evaluated': users_evaluated
        }
        
        print(f"üìà {dataset_name.title()} Ranking Results:")
        print(f"   mAP@10:  {ranking_results['mAP@10']:.4f}")
        print(f"   NDCG@10: {ranking_results['NDCG@10']:.4f}")
        print(f"   MRR@10:  {ranking_results['MRR@10']:.4f}")
        print(f"   Users:   {ranking_results['users_evaluated']}")
        
        return ranking_results
    
    def evaluate_business_impact(self, n_users: int = 100) -> Dict:
        """Evaluate business impact of recommendations"""
        print(f"\nüíº Evaluating business impact for {n_users} users...")
        
        if not self.business_engine:
            print("‚ùå Business engine not available")
            return {}
        
        # Sample random users
        user_ids = list(self.mappings['user_to_index'].keys())[:n_users]
        
        results = {
            'diversity_scores': [],
            'catalog_coverage': [],
            'popularity_bias': [],
            'cold_start_coverage': []
        }
        
        all_recommended_movies = set()
        
        for user_id in user_ids:
            # Generate recommendations
            recs = self.get_top_recommendations(user_id, n_recommendations=10)
            if not recs:
                continue
            
            movie_ids = [rec['movie_id'] for rec in recs]
            all_recommended_movies.update(movie_ids)
            
            # Calculate diversity (genre spread)
            genres = []
            for rec in recs:
                if 'genres' in rec and rec['genres']:
                    genres.extend(rec['genres'].split('|'))
            
            unique_genres = len(set(genres))
            diversity_score = unique_genres / len(genres) if genres else 0
            results['diversity_scores'].append(diversity_score)
            
            # Calculate popularity bias (how many popular vs niche movies)
            if hasattr(self.business_engine, 'popularity_scores'):
                popularities = [self.business_engine.popularity_scores.get(mid, 0.5) for mid in movie_ids]
                popularity_bias = np.mean(popularities)
                results['popularity_bias'].append(popularity_bias)
        
        # Calculate catalog coverage
        total_movies = len(self.mappings['movie_to_index'])
        coverage = len(all_recommended_movies) / total_movies
        results['catalog_coverage'] = coverage
        
        business_metrics = {
            'avg_diversity': float(np.mean(results['diversity_scores'])) if results['diversity_scores'] else 0.0,
            'catalog_coverage': float(coverage),
            'avg_popularity_bias': float(np.mean(results['popularity_bias'])) if results['popularity_bias'] else 0.5,
            'total_recommended_movies': len(all_recommended_movies),
            'users_evaluated': len(results['diversity_scores'])
        }
        
        print(f"üíº Business Impact Results:")
        print(f"   Avg Diversity:     {business_metrics['avg_diversity']:.4f}")
        print(f"   Catalog Coverage:  {business_metrics['catalog_coverage']:.4f}")
        print(f"   Popularity Bias:   {business_metrics['avg_popularity_bias']:.4f}")
        print(f"   Unique Movies Rec: {business_metrics['total_recommended_movies']}")
        
        return business_metrics
    
    def compare_business_rules_impact(self, n_users: int = 50) -> Dict:
        """Compare recommendations with and without business rules"""
        print(f"\nüîÑ Comparing business rules impact for {n_users} users...")
        
        user_ids = list(self.mappings['user_to_index'].keys())[:n_users]
        
        results = {
            'without_rules': {'diversity': [], 'avg_rating': []},
            'with_rules': {'diversity': [], 'avg_rating': []}
        }
        
        for user_id in user_ids:
            # Get recommendations without business rules
            recs_no_rules = self.get_top_recommendations(user_id, n_recommendations=10)
            
            # Create a sample user profile with business rules
            user_profile = UserProfile(
                user_id=user_id,
                genre_preferences={'Drama': 1.2, 'Comedy': 1.1},
                recency_bias=0.6,
                diversity_preference=0.4
            )
            
            # This is where we'd apply business rules (simplified for demo)
            recs_with_rules = self.get_top_recommendations(user_id, n_recommendations=10)
            
            # Calculate metrics for both
            for recs, key in [(recs_no_rules, 'without_rules'), (recs_with_rules, 'with_rules')]:
                if recs:
                    # Diversity (genre spread)
                    genres = []
                    ratings = []
                    for rec in recs:
                        if 'genres' in rec and rec['genres']:
                            genres.extend(rec['genres'].split('|'))
                        ratings.append(rec['predicted_rating'])
                    
                    diversity = len(set(genres)) / len(genres) if genres else 0
                    avg_rating = np.mean(ratings)
                    
                    results[key]['diversity'].append(diversity)
                    results[key]['avg_rating'].append(avg_rating)
        
        comparison = {
            'without_business_rules': {
                'avg_diversity': float(np.mean(results['without_rules']['diversity'])) if results['without_rules']['diversity'] else 0.0,
                'avg_predicted_rating': float(np.mean(results['without_rules']['avg_rating'])) if results['without_rules']['avg_rating'] else 0.0
            },
            'with_business_rules': {
                'avg_diversity': float(np.mean(results['with_rules']['diversity'])) if results['with_rules']['diversity'] else 0.0,
                'avg_predicted_rating': float(np.mean(results['with_rules']['avg_rating'])) if results['with_rules']['avg_rating'] else 0.0
            }
        }
        
        print(f"üîÑ Business Rules Comparison:")
        print(f"   Without Rules - Diversity: {comparison['without_business_rules']['avg_diversity']:.4f}, Rating: {comparison['without_business_rules']['avg_predicted_rating']:.4f}")
        print(f"   With Rules    - Diversity: {comparison['with_business_rules']['avg_diversity']:.4f}, Rating: {comparison['with_business_rules']['avg_predicted_rating']:.4f}")
        
        return comparison
    
    def run_comprehensive_evaluation(self) -> Dict:
        """Run all evaluations including business metrics"""
        print("üöÄ Starting comprehensive evaluation with business metrics...")
        start_time = time.time()
        
        results = super().run_full_evaluation()
        
        # Add ranking metrics
        if self.val_data is not None:
            results['ranking_metrics_val'] = self.evaluate_ranking_metrics(self.val_data, "validation")
        
        if self.test_data is not None:
            results['ranking_metrics_test'] = self.evaluate_ranking_metrics(self.test_data, "test")
        
        # Add business impact metrics
        results['business_impact'] = self.evaluate_business_impact()
        
        # Add business rules comparison
        results['business_rules_comparison'] = self.compare_business_rules_impact()
        
        evaluation_time = time.time() - start_time
        results['model_info']['evaluation_time'] = evaluation_time
        
        print(f"\n‚úÖ Comprehensive evaluation completed in {evaluation_time:.2f} seconds")
        
        return results

def main():
    parser = argparse.ArgumentParser(description='Advanced MovieLens VAE evaluation')
    parser.add_argument('--model_path', default='data/models/experiment_2_epoch086_val0.5996.pt', 
                       help='Path to trained model')
    parser.add_argument('--data_dir', default='data/processed',
                       help='Directory containing processed data')
    parser.add_argument('--output_file', default='advanced_evaluation_results.json',
                       help='Output file for results')
    
    args = parser.parse_args()
    
    # Run advanced evaluation
    evaluator = AdvancedModelEvaluator(args.model_path, args.data_dir)
    evaluator.load_model_and_data()
    results = evaluator.run_comprehensive_evaluation()
    
    # Save results
    with open(args.output_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nüìÑ Advanced evaluation results saved to {args.output_file}")
    print("\nüéâ Advanced evaluation complete!")

if __name__ == "__main__":
    main()