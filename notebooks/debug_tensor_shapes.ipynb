{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab2ercrni8m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TENSOR SHAPES ===\n",
      "states.shape: torch.Size([1024, 16])\n",
      "u_t.shape: torch.Size([1024, 64])\n",
      "dB_t.shape: torch.Size([1024, 16, 64])\n",
      "C.shape: torch.Size([16, 64])\n",
      "\n",
      "=== EINSUM 1: 'bsd,bd->bs' ===\n",
      "dB[:, t, :, :] should be [batch_size, d_state, d_model]\n",
      "u_t should be [batch_size, d_model]\n",
      "Result should be [batch_size, d_state]\n",
      "✅ First einsum succeeded: torch.Size([1024, 16])\n",
      "\n",
      "=== EINSUM 2: 'ds,bs->bd' ===\n",
      "C should be [d_state, d_model]\n",
      "states should be [batch_size, d_state]\n",
      "Result should be [batch_size, d_model]\n",
      "❌ Second einsum failed: einsum(): subscript s has size 16 for operand 1 which does not broadcast with previously seen size 64\n",
      "\n",
      "=== ANALYZING EINSUM 2 ===\n",
      "Current equation: 'ds,bs->bd'\n",
      "  d=d_state(16), s=d_state(16), b=batch_size(1024)\n",
      "  This expects C[d_state, d_state] but we have C[d_state, d_model]\n",
      "  The equation should probably be: 'dm,bm->bd' (not 'ds,bs->bd')\n",
      "\n",
      "Testing corrected equation 'dm,bm->bd':\n",
      "✅ Corrected einsum 'bs,sd->bd' succeeded: torch.Size([1024, 64])\n",
      "\n",
      "Alternative using matrix multiplication:\n",
      "✅ Matrix multiplication succeeded: torch.Size([1024, 64])\n"
     ]
    }
   ],
   "source": [
    "# Debug the final einsum issue - local paths\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/Users/nolanrobbins/Desktop/VS Code Projects/MovieLens-RecSys')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Debug both einsum operations with correct tensor dimensions\n",
    "batch_size = 1024\n",
    "d_model = 64\n",
    "d_state = 16\n",
    "\n",
    "# Create the tensors involved in the failing einsums\n",
    "states = torch.randn(batch_size, d_state)  # [1024, 16] \n",
    "u_t = torch.randn(batch_size, d_model)     # [1024, 64]  \n",
    "dB_t = torch.randn(batch_size, d_state, d_model)  # [1024, 16, 64]\n",
    "C = torch.randn(d_state, d_model)          # [16, 64]\n",
    "\n",
    "print(\"=== TENSOR SHAPES ===\")\n",
    "print(f\"states.shape: {states.shape}\")     # [1024, 16]\n",
    "print(f\"u_t.shape: {u_t.shape}\")           # [1024, 64]  \n",
    "print(f\"dB_t.shape: {dB_t.shape}\")         # [1024, 16, 64]\n",
    "print(f\"C.shape: {C.shape}\")               # [16, 64]\n",
    "\n",
    "print(\"\\n=== EINSUM 1: 'bsd,bd->bs' ===\")\n",
    "print(\"dB[:, t, :, :] should be [batch_size, d_state, d_model]\")\n",
    "print(\"u_t should be [batch_size, d_model]\") \n",
    "print(\"Result should be [batch_size, d_state]\")\n",
    "try:\n",
    "    result1 = torch.einsum('bsd,bd->bs', dB_t, u_t)\n",
    "    print(f\"✅ First einsum succeeded: {result1.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ First einsum failed: {e}\")\n",
    "\n",
    "print(\"\\n=== EINSUM 2: 'ds,bs->bd' ===\")  \n",
    "print(\"C should be [d_state, d_model]\")\n",
    "print(\"states should be [batch_size, d_state]\")\n",
    "print(\"Result should be [batch_size, d_model]\")\n",
    "try:\n",
    "    result2 = torch.einsum('ds,bs->bd', C, states)\n",
    "    print(f\"✅ Second einsum succeeded: {result2.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Second einsum failed: {e}\")\n",
    "\n",
    "# The issue might be that the einsum equation is wrong. Let's check what should happen:\n",
    "print(\"\\n=== ANALYZING EINSUM 2 ===\")\n",
    "print(\"Current equation: 'ds,bs->bd'\")\n",
    "print(\"  d=d_state(16), s=d_state(16), b=batch_size(1024)\")  \n",
    "print(\"  This expects C[d_state, d_state] but we have C[d_state, d_model]\")\n",
    "print(\"  The equation should probably be: 'dm,bm->bd' (not 'ds,bs->bd')\")\n",
    "\n",
    "print(f\"\\nTesting corrected equation 'dm,bm->bd':\")\n",
    "try:\n",
    "    # This should be the correct einsum for C[d_state, d_model] * states[batch, d_state] \n",
    "    # But wait, that doesn't make sense either...\n",
    "    \n",
    "    # Let's think: if we want [batch_size, d_model] output\n",
    "    # And we have C[d_state, d_model] and states[batch_size, d_state]\n",
    "    # Then we want: states @ C = [batch_size, d_state] @ [d_state, d_model] = [batch_size, d_model]\n",
    "    result2_corrected = torch.einsum('bs,sd->bd', states, C)\n",
    "    print(f\"✅ Corrected einsum 'bs,sd->bd' succeeded: {result2_corrected.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Corrected einsum failed: {e}\")\n",
    "    \n",
    "print(f\"\\nAlternative using matrix multiplication:\")\n",
    "try:\n",
    "    result_matmul = states @ C  # [1024, 16] @ [16, 64] = [1024, 64]\n",
    "    print(f\"✅ Matrix multiplication succeeded: {result_matmul.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Matrix multiplication failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f4a75e-f796-4fa9-8cc0-b197dd46bbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/MovieLens-RecSys/.venv/lib/python3.11/site-packages')\n",
    "sys.path.append('/MovieLens-RecSys')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Now we can debug the tensor shapes and imports\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7ae936-fb14-40cd-ac1f-dc18c151f73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S5Layer imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import S5Layer with correct local paths\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/Users/nolanrobbins/Desktop/VS Code Projects/MovieLens-RecSys')\n",
    "\n",
    "from models.sota_2025.components.state_space_models import S5Layer\n",
    "\n",
    "print(\"S5Layer imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fcf3b24-6849-4f99-ad50-aef3c4b43e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([1024, 200, 64])\n",
      "time_intervals.shape: torch.Size([1024, 199])\n",
      "time_intervals expected shape: (1024, 200)\n"
     ]
    }
   ],
   "source": [
    "# Create tensors with the same dimensions as your training\n",
    "batch_size = 1024\n",
    "seq_len = 200\n",
    "d_model = 64  # Typical embedding dimension\n",
    "\n",
    "# Simulate the inputs that are causing the problem\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "time_intervals = torch.randn(batch_size, seq_len - 1)  # This is likely the issue - seq_len-1\n",
    "\n",
    "print(f\"x.shape: {x.shape}\")\n",
    "print(f\"time_intervals.shape: {time_intervals.shape}\")\n",
    "print(f\"time_intervals expected shape: {(batch_size, seq_len)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e66180a-8d2b-4b67-8c20-03903513202f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ S5Layer forward pass succeeded!\n",
      "Output shape: torch.Size([1024, 200, 64])\n"
     ]
    }
   ],
   "source": [
    "# Create an S5Layer instance\n",
    "s5_layer = S5Layer(d_model=d_model, d_state=16)\n",
    "\n",
    "# Try the forward pass that's failing\n",
    "try:\n",
    "    output = s5_layer(x, time_intervals)\n",
    "    print(\"✅ S5Layer forward pass succeeded!\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in S5Layer: {e}\")\n",
    "    print(\"This is the exact error we need to fix!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8746a487-6aa8-4b13-84a8-d9bed27a4647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_intervals.shape: torch.Size([1024, 199])\n",
      "batch_size: 1024, current_len: 199\n",
      "dt.shape: torch.Size([1024, 200, 1])\n",
      "expected_len: 200\n",
      "Need to pad: 199 -> 200\n",
      "padding.shape: torch.Size([1024, 1])\n",
      "time_intervals_padded.shape: torch.Size([1024, 200])\n",
      "dt.squeeze(-1).shape: torch.Size([1024, 200])\n",
      "time_intervals_padded.unsqueeze(-1).shape: torch.Size([1024, 200, 1])\n",
      "❌ Still failing: The size of tensor a (1024) must match the size of tensor b (200) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "# Let's see what happens in the S5Layer forward method step by step\n",
    "d_model = 64\n",
    "d_state = 16\n",
    "\n",
    "# Simulate the problematic part\n",
    "batch_size, current_len = time_intervals.shape\n",
    "print(f\"time_intervals.shape: {time_intervals.shape}\")\n",
    "print(f\"batch_size: {batch_size}, current_len: {current_len}\")\n",
    "\n",
    "# Create dt tensor like in the model\n",
    "dt = torch.randn(batch_size, 200, 1)  # This should match seq_len\n",
    "expected_len = dt.shape[1]\n",
    "print(f\"dt.shape: {dt.shape}\")\n",
    "print(f\"expected_len: {expected_len}\")\n",
    "\n",
    "# Test the padding logic from my fix\n",
    "if current_len < expected_len:\n",
    "    print(f\"Need to pad: {current_len} -> {expected_len}\")\n",
    "    padding = time_intervals[:, -1:].expand(batch_size, expected_len -\n",
    "current_len)\n",
    "    print(f\"padding.shape: {padding.shape}\")\n",
    "    time_intervals_padded = torch.cat([time_intervals, padding], dim=1)\n",
    "    print(f\"time_intervals_padded.shape: {time_intervals_padded.shape}\")\n",
    "else:\n",
    "    time_intervals_padded = time_intervals\n",
    "\n",
    "# Test the final operation\n",
    "dt_squeezed = dt.squeeze(-1)\n",
    "time_padded_unsqueezed = time_intervals_padded.unsqueeze(-1)\n",
    "\n",
    "print(f\"dt.squeeze(-1).shape: {dt_squeezed.shape}\")\n",
    "print(f\"time_intervals_padded.unsqueeze(-1).shape: {time_padded_unsqueezed.shape}\")\n",
    "\n",
    "# This should work now\n",
    "try:\n",
    "    result = dt_squeezed * time_padded_unsqueezed\n",
    "    print(\"✅ Tensor multiplication succeeded!\")\n",
    "    print(f\"Result shape: {result.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Still failing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09a55aaf-72fd-4059-a06b-ac856f4d99bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x.shape: torch.Size([1024, 200, 64])\n",
      "Input time_intervals.shape: torch.Size([1024, 199])\n",
      "dt.shape after projection: torch.Size([1024, 200, 1])\n",
      "time_intervals: batch_size=1024, current_len=199\n",
      "dt: expected_len=200\n",
      "After padding: torch.Size([1024, 200])\n",
      "Before multiplication:\n",
      "  dt.squeeze(-1).shape: torch.Size([1024, 200])\n",
      "  time_intervals_padded.unsqueeze(-1).shape: torch.Size([1024, 200, 1])\n",
      "❌ Debug layer failed: The size of tensor a (1024) must match the size of tensor b (200) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "# Let's step through the S5Layer forward method manually\n",
    "import torch.nn as nn\n",
    "\n",
    "class DebugS5Layer(nn.Module):\n",
    "    def __init__(self, d_model, d_state):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_state = d_state\n",
    "\n",
    "        # Same initialization as S5Layer\n",
    "        self.dt_proj = nn.Linear(d_model, 1)\n",
    "        self.dt_min = 1e-3\n",
    "        self.dt_max = 1e-1\n",
    "        self.A_log = nn.Parameter(torch.randn(d_state))\n",
    "        self.B = nn.Parameter(torch.randn(d_state, d_model))\n",
    "        self.C = nn.Parameter(torch.randn(d_state, d_model))\n",
    "\n",
    "    def forward(self, x, time_intervals=None):\n",
    "        print(f\"Input x.shape: {x.shape}\")\n",
    "        print(f\"Input time_intervals.shape: {time_intervals.shape if time_intervals is not None else None}\")\n",
    "\n",
    "        # Compute dt\n",
    "        dt = self.dt_proj(x)  # [batch_size, seq_len, 1]\n",
    "        dt = torch.sigmoid(dt) * (self.dt_max - self.dt_min) + self.dt_min\n",
    "        print(f\"dt.shape after projection: {dt.shape}\")\n",
    "\n",
    "        # Debug the time_intervals handling\n",
    "        if time_intervals is not None:\n",
    "            batch_size, current_len = time_intervals.shape\n",
    "            expected_len = dt.shape[1]\n",
    "            print(f\"time_intervals: batch_size={batch_size}, current_len={current_len}\")\n",
    "            print(f\"dt: expected_len={expected_len}\")\n",
    "\n",
    "            if current_len < expected_len:\n",
    "                padding = time_intervals[:, -1:].expand(batch_size, expected_len - current_len)\n",
    "                time_intervals_padded = torch.cat([time_intervals, padding], dim=1)\n",
    "                print(f\"After padding: {time_intervals_padded.shape}\")\n",
    "            else:\n",
    "                time_intervals_padded = time_intervals\n",
    "                print(f\"No padding needed: {time_intervals_padded.shape}\")\n",
    "\n",
    "            print(f\"Before multiplication:\")\n",
    "            print(f\"  dt.squeeze(-1).shape: {dt.squeeze(-1).shape}\")\n",
    "            print(f\"  time_intervals_padded.unsqueeze(-1).shape: {time_intervals_padded.unsqueeze(-1).shape}\")\n",
    "\n",
    "            # This is the line that's failing\n",
    "            dt = dt.squeeze(-1) * time_intervals_padded.unsqueeze(-1)\n",
    "            print(f\"After multiplication: dt.shape = {dt.shape}\")\n",
    "\n",
    "        return x  # Just return x for debugging\n",
    "\n",
    "# Test with debug layer\n",
    "debug_s5 = DebugS5Layer(d_model=64, d_state=16)\n",
    "try:\n",
    "    output = debug_s5(x, time_intervals)\n",
    "    print(\"✅ Debug layer succeeded!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Debug layer failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ddfdd4d-1603-4f17-98b8-927ad1a409b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TENSOR ANALYSIS ===\n",
      "dt_squeezed.shape: torch.Size([1024, 200])\n",
      "dt_squeezed.stride(): (200, 1)\n",
      "dt_squeezed.is_contiguous(): True\n",
      "\n",
      "time_padded_unsqueezed.shape: torch.Size([1024, 200, 1])\n",
      "time_padded_unsqueezed.stride(): (200, 1, 1)\n",
      "time_padded_unsqueezed.is_contiguous(): True\n",
      "\n",
      "=== ATTEMPTING DIFFERENT APPROACHES ===\n",
      "❌ Approach 1 failed: The size of tensor a (1024) must match the size of tensor b (200) at non-singleton dimension 1\n",
      "✅ Approach 2 (reshape) succeeded!\n",
      "Result2 shape: torch.Size([1024, 200])\n",
      "Broadcasting shapes: torch.Size([1024, 200]) * torch.Size([1024, 200])\n",
      "✅ Approach 3 (torch.mul) succeeded!\n",
      "Result3 shape: torch.Size([1024, 200])\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the exact tensors and their properties\n",
    "dt_squeezed = dt.squeeze(-1)\n",
    "time_padded_unsqueezed = time_intervals_padded.unsqueeze(-1)\n",
    "\n",
    "print(\"=== TENSOR ANALYSIS ===\")\n",
    "print(f\"dt_squeezed.shape: {dt_squeezed.shape}\")\n",
    "print(f\"dt_squeezed.stride(): {dt_squeezed.stride()}\")\n",
    "print(f\"dt_squeezed.is_contiguous(): {dt_squeezed.is_contiguous()}\")\n",
    "\n",
    "print(f\"\\ntime_padded_unsqueezed.shape: {time_padded_unsqueezed.shape}\")\n",
    "print(f\"time_padded_unsqueezed.stride(): {time_padded_unsqueezed.stride()}\")\n",
    "print(f\"time_padded_unsqueezed.is_contiguous(): {time_padded_unsqueezed.is_contiguous()}\")\n",
    "\n",
    "print(\"\\n=== ATTEMPTING DIFFERENT APPROACHES ===\")\n",
    "\n",
    "# Approach 1: Make tensors contiguous\n",
    "try:\n",
    "    result1 = dt_squeezed.contiguous() * time_padded_unsqueezed.contiguous()\n",
    "    print(\"✅ Approach 1 (contiguous) succeeded!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Approach 1 failed: {e}\")\n",
    "\n",
    "# Approach 2: Different dimension handling\n",
    "try:\n",
    "    # Instead of squeeze/unsqueeze, let's try different reshaping\n",
    "    dt_reshaped = dt.view(1024, 200)  # [batch, seq_len]\n",
    "    time_reshaped = time_intervals_padded  # Already [batch, seq_len]\n",
    "    result2 = dt_reshaped * time_reshaped\n",
    "    print(\"✅ Approach 2 (reshape) succeeded!\")\n",
    "    print(f\"Result2 shape: {result2.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Approach 2 failed: {e}\")\n",
    "\n",
    "# Approach 3: Element-wise with explicit broadcasting\n",
    "try:\n",
    "    dt_for_broadcast = dt.squeeze(-1)  # [1024, 200]\n",
    "    time_for_broadcast = time_intervals_padded  # [1024, 200]\n",
    "    print(f\"Broadcasting shapes: {dt_for_broadcast.shape} * {time_for_broadcast.shape}\")\n",
    "    result3 = torch.mul(dt_for_broadcast, time_for_broadcast)\n",
    "    print(\"✅ Approach 3 (torch.mul) succeeded!\")\n",
    "    print(f\"Result3 shape: {result3.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Approach 3 failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "243a7dbf-5f05-40a9-bbf8-ead4622a2713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fixed S5Layer succeeded!\n"
     ]
    }
   ],
   "source": [
    "# Test the fixed approach in the S5Layer\n",
    "class FixedS5Layer(nn.Module):\n",
    "    def __init__(self, d_model, d_state):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_state = d_state\n",
    "        self.dt_proj = nn.Linear(d_model, 1)\n",
    "        self.dt_min = 1e-3\n",
    "        self.dt_max = 1e-1\n",
    "        self.A_log = nn.Parameter(torch.randn(d_state))\n",
    "        self.B = nn.Parameter(torch.randn(d_state, d_model))\n",
    "        self.C = nn.Parameter(torch.randn(d_state, d_model))\n",
    "\n",
    "    def forward(self, x, time_intervals=None):\n",
    "        dt = self.dt_proj(x)\n",
    "        dt = torch.sigmoid(dt) * (self.dt_max - self.dt_min) + self.dt_min\n",
    "\n",
    "        if time_intervals is not None:\n",
    "            batch_size, current_len = time_intervals.shape\n",
    "            expected_len = dt.shape[1]\n",
    "\n",
    "            if current_len < expected_len:\n",
    "                padding = time_intervals[:, -1:].expand(batch_size, expected_len - current_len)\n",
    "                time_intervals_padded = torch.cat([time_intervals, padding], dim=1)\n",
    "            else:\n",
    "                time_intervals_padded = time_intervals\n",
    "\n",
    "            # FIXED LINE: Use view instead of squeeze/unsqueeze\n",
    "            dt = dt.view(batch_size, expected_len) * time_intervals_padded\n",
    "            dt = dt.unsqueeze(-1)  # Add back the last dimension for later operations\n",
    "\n",
    "        return x  # Return input for testing\n",
    "\n",
    "# Test the fix\n",
    "fixed_s5 = FixedS5Layer(d_model=64, d_state=16)\n",
    "try:\n",
    "    output = fixed_s5(x, time_intervals)\n",
    "    print(\"✅ Fixed S5Layer succeeded!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Fixed S5Layer failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14272d29-6f5f-4521-968a-db0086d5fdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt.shape: torch.Size([1024, 200, 1])\n",
      "time_intervals.shape: torch.Size([1024, 199])\n",
      "time_intervals_padded.shape: torch.Size([1024, 200])\n",
      "time_intervals_padded.unsqueeze(-1).shape: torch.Size([1024, 200, 1])\n",
      "✅ New approach succeeded! Result shape: torch.Size([1024, 200, 1])\n"
     ]
    }
   ],
   "source": [
    "# Test the new approach: dt * time_intervals_padded.unsqueeze(-1)\n",
    "batch_size = 1024\n",
    "seq_len = 200\n",
    "d_model = 64\n",
    "\n",
    "# Create the same tensors as before\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "time_intervals = torch.randn(batch_size, seq_len - 1)  # [1024, 199]\n",
    "\n",
    "# Simulate dt computation\n",
    "dt = torch.randn(batch_size, seq_len, 1)  # [batch_size, seq_len, 1] - original shape\n",
    "\n",
    "print(f\"dt.shape: {dt.shape}\")\n",
    "print(f\"time_intervals.shape: {time_intervals.shape}\")\n",
    "\n",
    "# Do the padding\n",
    "batch_size, current_len = time_intervals.shape\n",
    "expected_len = dt.shape[1]\n",
    "padding = time_intervals[:, -1:].expand(batch_size, expected_len - current_len)\n",
    "time_intervals_padded = torch.cat([time_intervals, padding], dim=1)\n",
    "\n",
    "print(f\"time_intervals_padded.shape: {time_intervals_padded.shape}\")\n",
    "print(f\"time_intervals_padded.unsqueeze(-1).shape: {time_intervals_padded.unsqueeze(-1).shape}\")\n",
    "\n",
    "# Test the new multiplication approach\n",
    "try:\n",
    "    result = dt * time_intervals_padded.unsqueeze(-1)\n",
    "    print(f\"✅ New approach succeeded! Result shape: {result.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ New approach failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96261756-62b1-4767-b3a7-28b28399f156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt.shape before dA/dB: torch.Size([1024, 200, 1])\n",
      "dA.shape: torch.Size([1024, 200, 1, 16])\n",
      "dB.shape: torch.Size([1024, 200, 16, 64])\n",
      "✅ Final S5Layer with all operations succeeded!\n"
     ]
    }
   ],
   "source": [
    "class FinalS5Layer(nn.Module):\n",
    "    def __init__(self, d_model, d_state):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_state = d_state\n",
    "        self.dt_proj = nn.Linear(d_model, 1)\n",
    "        self.dt_min = 1e-3\n",
    "        self.dt_max = 1e-1\n",
    "        self.A_log = nn.Parameter(torch.randn(d_state))\n",
    "        self.B = nn.Parameter(torch.randn(d_state, d_model))\n",
    "        self.C = nn.Parameter(torch.randn(d_state, d_model))\n",
    "\n",
    "    def forward(self, x, time_intervals=None):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        dt = self.dt_proj(x)\n",
    "        dt = torch.sigmoid(dt) * (self.dt_max - self.dt_min) + self.dt_min\n",
    "\n",
    "        if time_intervals is not None:\n",
    "            batch_size, current_len = time_intervals.shape\n",
    "            expected_len = dt.shape[1]\n",
    "\n",
    "            if current_len < expected_len:\n",
    "                padding = time_intervals[:, -1:].expand(batch_size, expected_len - current_len)\n",
    "                time_intervals_padded = torch.cat([time_intervals, padding], dim=1)\n",
    "            else:\n",
    "                time_intervals_padded = time_intervals\n",
    "\n",
    "            # FINAL FIX: Proper broadcasting maintaining tensor dimensions\n",
    "            dt = dt * time_intervals_padded.unsqueeze(-1)\n",
    "\n",
    "        # Test the downstream operations that were failing\n",
    "        A = -torch.exp(self.A_log)\n",
    "        print(f\"dt.shape before dA/dB: {dt.shape}\")\n",
    "        dA = torch.exp(dt.unsqueeze(-1) * A.unsqueeze(0).unsqueeze(0))\n",
    "        dB = (dt.unsqueeze(-1) * self.B.unsqueeze(0).unsqueeze(0))\n",
    "        print(f\"dA.shape: {dA.shape}\")\n",
    "        print(f\"dB.shape: {dB.shape}\")\n",
    "\n",
    "        return x\n",
    "\n",
    "# Test the final fix\n",
    "final_s5 = FinalS5Layer(d_model=64, d_state=16)\n",
    "try:\n",
    "    output = final_s5(x, time_intervals)\n",
    "    print(\"✅ Final S5Layer with all operations succeeded!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Final S5Layer failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35ee2a26-d170-42d4-8318-7f14196673fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TENSOR SHAPES ===\n",
      "dt.shape: torch.Size([1024, 200, 1])\n",
      "A.shape: torch.Size([16])\n",
      "B.shape: torch.Size([16, 64])\n",
      "C.shape: torch.Size([16, 64])\n",
      "dA.shape: torch.Size([1024, 200, 1, 16])\n",
      "dB.shape: torch.Size([1024, 200, 16, 64])\n",
      "Initial states.shape: torch.Size([1024, 16])\n",
      "u_t.shape: torch.Size([1024, 64])\n",
      "✅ States update succeeded: torch.Size([1024, 1024, 16])\n",
      "❌ Output computation failed: einsum(): the number of subscripts in the equation (2) does not match the number of dimensions (3) for operand 1 and no ellipsis was given\n",
      "Expected: C.shape=torch.Size([16, 64]), states.shape=torch.Size([1024, 1024, 16])\n",
      "C dimensions: 2, states dimensions: 3\n"
     ]
    }
   ],
   "source": [
    "# Debug the states computation that's failing\n",
    "batch_size = 1024\n",
    "seq_len = 200\n",
    "d_model = 64\n",
    "d_state = 16\n",
    "\n",
    "# Simulate the tensors that should be created\n",
    "dt = torch.randn(batch_size, seq_len, 1)  # After our fix\n",
    "A = torch.randn(d_state)\n",
    "B = torch.randn(d_state, d_model)\n",
    "C = torch.randn(d_state, d_model)\n",
    "\n",
    "print(\"=== TENSOR SHAPES ===\")\n",
    "print(f\"dt.shape: {dt.shape}\")\n",
    "print(f\"A.shape: {A.shape}\")\n",
    "print(f\"B.shape: {B.shape}\")\n",
    "print(f\"C.shape: {C.shape}\")\n",
    "\n",
    "# Compute dA and dB like in the original code\n",
    "dA = torch.exp(dt.unsqueeze(-1) * A.unsqueeze(0).unsqueeze(0))  # [batch_size, seq_len, d_state]\n",
    "dB = (dt.unsqueeze(-1) * B.unsqueeze(0).unsqueeze(0))  # [batch_size, seq_len, d_state, d_model]\n",
    "\n",
    "print(f\"dA.shape: {dA.shape}\")\n",
    "print(f\"dB.shape: {dB.shape}\")\n",
    "\n",
    "# Initialize states\n",
    "states = torch.zeros(batch_size, d_state)\n",
    "print(f\"Initial states.shape: {states.shape}\")\n",
    "\n",
    "# Simulate the first iteration of the loop\n",
    "t = 0\n",
    "x = torch.randn(batch_size, seq_len, d_model)  # Input tensor\n",
    "u_t = x[:, t, :]  # [batch_size, d_model]\n",
    "print(f\"u_t.shape: {u_t.shape}\")\n",
    "\n",
    "# This is the problematic line 125\n",
    "try:\n",
    "    new_states = dA[:, t, :] * states + torch.einsum('bsd,bd->bs', dB[:, t, :, :], u_t)\n",
    "    print(f\"✅ States update succeeded: {new_states.shape}\")\n",
    "    states = new_states\n",
    "except Exception as e:\n",
    "    print(f\"❌ States update failed: {e}\")\n",
    "\n",
    "# This is the problematic line 128\n",
    "try:\n",
    "    y_t = torch.einsum('ds,bs->bd', C, states)\n",
    "    print(f\"✅ Output computation succeeded: {y_t.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Output computation failed: {e}\")\n",
    "    print(f\"Expected: C.shape={C.shape}, states.shape={states.shape}\")\n",
    "    print(f\"C dimensions: {len(C.shape)}, states dimensions: {len(states.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab9e3a49-a62d-48c9-9804-cd35335de1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEBUGGING dA MULTIPLICATION ===\n",
      "dA.shape: torch.Size([1024, 200, 1, 16])\n",
      "dA[:, t, :].shape: torch.Size([1024, 1, 16])\n",
      "dA_t.shape: torch.Size([1024, 1, 16])\n",
      "states.shape: torch.Size([1024, 16])\n",
      "dA_t * states result shape: torch.Size([1024, 1024, 16])\n",
      "\n",
      "=== TESTING THE FIX ===\n",
      "dA_t_fixed.shape: torch.Size([1024, 16])\n",
      "dA_t_fixed * states shape: torch.Size([1024, 16])\n",
      "einsum result shape: torch.Size([1024, 16])\n",
      "Final states shape: torch.Size([1024, 16])\n"
     ]
    }
   ],
   "source": [
    "# Debug the problematic multiplication\n",
    "print(\"=== DEBUGGING dA MULTIPLICATION ===\")\n",
    "print(f\"dA.shape: {dA.shape}\")  # [1024, 200, 1, 16]\n",
    "print(f\"dA[:, t, :].shape: {dA[:, t, :].shape}\")  # This is the problem!\n",
    "\n",
    "# The issue: dA[:, t, :] should be [1024, 16], but it's [1024, 1, 16]\n",
    "dA_t = dA[:, t, :]  # [1024, 1, 16] \n",
    "states = torch.zeros(batch_size, d_state)  # [1024, 16]\n",
    "\n",
    "print(f\"dA_t.shape: {dA_t.shape}\")\n",
    "print(f\"states.shape: {states.shape}\")\n",
    "\n",
    "# This multiplication creates wrong shape due to broadcasting\n",
    "result = dA_t * states\n",
    "print(f\"dA_t * states result shape: {result.shape}\")  # This will be wrong!\n",
    "\n",
    "# The fix: we need to squeeze the extra dimension\n",
    "print(\"\\n=== TESTING THE FIX ===\")\n",
    "dA_t_fixed = dA[:, t, :].squeeze(1)  # Remove the singleton dimension\n",
    "print(f\"dA_t_fixed.shape: {dA_t_fixed.shape}\")\n",
    "\n",
    "result_fixed = dA_t_fixed * states\n",
    "print(f\"dA_t_fixed * states shape: {result_fixed.shape}\")\n",
    "\n",
    "# Test the full computation with the fix\n",
    "einsum_result = torch.einsum('bsd,bd->bs', dB[:, t, :, :], u_t)\n",
    "print(f\"einsum result shape: {einsum_result.shape}\")\n",
    "\n",
    "final_states = dA_t_fixed * states + einsum_result\n",
    "print(f\"Final states shape: {final_states.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e86970d6-edcc-4c48-83c3-a417610df722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Complete S5Layer failed: einsum(): subscript s has size 16 for operand 1 which does not broadcast with previously seen size 64\n"
     ]
    }
   ],
   "source": [
    "class CompleteS5Layer(nn.Module):\n",
    "    def __init__(self, d_model, d_state):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_state = d_state\n",
    "        self.dt_proj = nn.Linear(d_model, 1)\n",
    "        self.dt_min = 1e-3\n",
    "        self.dt_max = 1e-1\n",
    "        self.A_log = nn.Parameter(torch.randn(d_state))\n",
    "        self.B = nn.Parameter(torch.randn(d_state, d_model))\n",
    "        self.C = nn.Parameter(torch.randn(d_state, d_model))\n",
    "        self.D = nn.Parameter(torch.zeros(d_model))  # Add D parameter\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, time_intervals=None):\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "\n",
    "        # Compute dt\n",
    "        dt = self.dt_proj(x)\n",
    "        dt = torch.sigmoid(dt) * (self.dt_max - self.dt_min) + self.dt_min\n",
    "\n",
    "        # Apply time intervals\n",
    "        if time_intervals is not None:\n",
    "            batch_size, current_len = time_intervals.shape\n",
    "            expected_len = dt.shape[1]\n",
    "\n",
    "            if current_len < expected_len:\n",
    "                padding = time_intervals[:, -1:].expand(batch_size, expected_len - current_len)\n",
    "                time_intervals_padded = torch.cat([time_intervals, padding], dim=1)\n",
    "            else:\n",
    "                time_intervals_padded = time_intervals\n",
    "\n",
    "            dt = dt * time_intervals_padded.unsqueeze(-1)\n",
    "\n",
    "        # State space matrices\n",
    "        A = -torch.exp(self.A_log)\n",
    "        dA = torch.exp(dt.unsqueeze(-1) * A.unsqueeze(0).unsqueeze(0))\n",
    "        dB = (dt.unsqueeze(-1) * self.B.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "        # State space computation\n",
    "        states = torch.zeros(batch_size, self.d_state, device=x.device, dtype=x.dtype)\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            u_t = x[:, t, :]\n",
    "            # FIXED: squeeze the singleton dimension\n",
    "            states = dA[:, t, :].squeeze(1) * states + torch.einsum('bsd,bd->bs', dB[:, t, :, :], u_t)\n",
    "            y_t = torch.einsum('ds,bs->bd', self.C, states) + self.D * u_t\n",
    "            outputs.append(y_t)\n",
    "\n",
    "        output = torch.stack(outputs, dim=1)\n",
    "        return self.norm(output)\n",
    "\n",
    "# Test with actual tensor shapes\n",
    "complete_s5 = CompleteS5Layer(d_model=64, d_state=16)\n",
    "try:\n",
    "    output = complete_s5(x, time_intervals)\n",
    "    print(f\"✅ Complete S5Layer succeeded! Output shape: {output.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Complete S5Layer failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad771601-ddf7-413d-9238-3659be82c08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ RecBole import failed: No module named 'recbole'\n"
     ]
    }
   ],
   "source": [
    "# Check what RecBole has for SS4Rec\n",
    "try:\n",
    "    from recbole.model.sequential_recommender import SASRec\n",
    "    from recbole.config import Config\n",
    "    from recbole.data import create_dataset, data_preparation\n",
    "    print(\"✅ RecBole is available!\")\n",
    "    print(\"Available sequential models in RecBole:\")\n",
    "\n",
    "    # List some common sequential models in RecBole\n",
    "    models = ['SASRec', 'BERT4Rec', 'GRU4Rec', 'NextItNet']\n",
    "    for model in models:\n",
    "        try:\n",
    "            exec(f\"from recbole.model.sequential_recommender import {model}\")\n",
    "            print(f\"  ✅ {model}\")\n",
    "        except:\n",
    "            print(f\"  ❌ {model}\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"❌ RecBole import failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f26ae6-55e6-41f6-9c66-124ff9113be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
