{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f03084f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import copy\n",
    "from itertools import zip_longest\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c7ce4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(state=1):\n",
    "    gens = (np.random.seed, torch.manual_seed, torch.cuda.manual_seed)\n",
    "    for set_state in gens:\n",
    "        set_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de3e8139",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e38a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LINK='https://files.grouplens.org/datasets/movielens/ml-32m.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "677a592b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nzip_filename = DATASET_LINK.split('/')[-1]\\n''This script downloads the MovieLens 32M dataset if it is not already present, and extracts it\\nfrom the zip file. The dataset is used for building recommendation systems.''\\n\\n# Download the dataset if not already present\\nif not os.path.exists(zip_filename):\\n\\timport ssl\\n\\tcontext = ssl._create_unverified_context()\\n\\turllib.request.urlretrieve(DATASET_LINK, zip_filename)\\n\\n# Unzip the file if not already extracted\\nwith zipfile.ZipFile(zip_filename, 'r') as zip_ref:\\n\\tzip_ref.extractall()\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "'''\n",
    "zip_filename = DATASET_LINK.split('/')[-1]\n",
    "''This script downloads the MovieLens 32M dataset if it is not already present, and extracts it\n",
    "from the zip file. The dataset is used for building recommendation systems.''\n",
    "\n",
    "# Download the dataset if not already present\n",
    "if not os.path.exists(zip_filename):\n",
    "\timport ssl\n",
    "\tcontext = ssl._create_unverified_context()\n",
    "\turllib.request.urlretrieve(DATASET_LINK, zip_filename)\n",
    "\n",
    "# Unzip the file if not already extracted\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "\tzip_ref.extractall()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4474fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    files = {}\n",
    "    for filename in os.listdir(path):\n",
    "        stem, suffix =  os.path.splitext(filename)\n",
    "        file_path = os.path.join(path,filename)\n",
    "        print(filename)\n",
    "        if suffix == '.csv':\n",
    "            files[stem] = pd.read_csv(file_path)\n",
    "        elif suffix == '.dat':\n",
    "            if stem == 'ratings':\n",
    "                columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "            else:\n",
    "                columns = ['movieId', 'title', 'genres']\n",
    "            data = pd.read_csv(file_path, sep='::', names=columns, engine='python')\n",
    "            files[stem] = data\n",
    "    return files['ratings'], files['movies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff2570e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing data from: /Users/nolanrobbins/Desktop/VS Code Projects/MovieLens-RecSys/data/raw\n",
      "links.csv\n",
      "tags.csv\n",
      "checksums.txt\n",
      "ratings.csv\n",
      "README.txt\n",
      "movies.csv\n"
     ]
    }
   ],
   "source": [
    "# Use existing data in data/raw directory (skip download/extraction)\n",
    "extracted_dir = '/Users/nolanrobbins/Desktop/VS Code Projects/MovieLens-RecSys/data/raw'\n",
    "print(f\"Using existing data from: {extracted_dir}\")\n",
    "\n",
    "# Read data from the raw directory\n",
    "ratings, movies = read_data(extracted_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fc243bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944250228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>943230976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>943228858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1       17     4.0  944249077\n",
       "1       1       25     1.0  944250228\n",
       "2       1       29     2.0  943230976\n",
       "3       1       30     5.0  944249077\n",
       "4       1       32     5.0  943228858"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "291b68ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating range: (np.float64(0.5), np.float64(5.0))\n"
     ]
    }
   ],
   "source": [
    "minmax = ratings.rating.min(), ratings.rating.max()\n",
    "print(f\"Rating range: {minmax}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d62e66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13058938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87585, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6cfda9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.merge(movies[[\"movieId\", \"title\"]], on=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "105c4316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>944249077</td>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944250228</td>\n",
       "      <td>Leaving Las Vegas (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>943230976</td>\n",
       "      <td>City of Lost Children, The (Cité des enfants p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>944249077</td>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>943228858</td>\n",
       "      <td>Twelve Monkeys (a.k.a. 12 Monkeys) (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp  \\\n",
       "0       1       17     4.0  944249077   \n",
       "1       1       25     1.0  944250228   \n",
       "2       1       29     2.0  943230976   \n",
       "3       1       30     5.0  944249077   \n",
       "4       1       32     5.0  943228858   \n",
       "\n",
       "                                               title  \n",
       "0                       Sense and Sensibility (1995)  \n",
       "1                           Leaving Las Vegas (1995)  \n",
       "2  City of Lost Children, The (Cité des enfants p...  \n",
       "3  Shanghai Triad (Yao a yao yao dao waipo qiao) ...  \n",
       "4          Twelve Monkeys (a.k.a. 12 Monkeys) (1995)  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6456ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabular_preview(ratings, n=15):\n",
    "    \"\"\"Creates a cross-tabular view of users vs movies.\"\"\"\n",
    "    \n",
    "    user_groups = ratings.groupby('userId')['rating'].count()\n",
    "    top_users = user_groups.sort_values(ascending=False)[:n]\n",
    "\n",
    "    movie_groups = ratings.groupby('movieId')['rating'].count()\n",
    "    top_movies = movie_groups.sort_values(ascending=False)[:n]\n",
    "\n",
    "    top = (\n",
    "        ratings.\n",
    "        join(top_users, rsuffix='_r', how='inner', on='userId').\n",
    "        join(top_movies, rsuffix='_r', how='inner', on='movieId'))\n",
    "\n",
    "    return pd.crosstab(top.userId, top.movieId, top.rating, aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6cacce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7t/pvkx_dbx3hn67b1jjpbrc37c0000gn/T/ipykernel_20716/3933855387.py:15: FutureWarning: The provided callable <function sum at 0x1211fade0> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  return pd.crosstab(top.userId, top.movieId, top.rating, aggfunc=np.sum)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>50</th>\n",
       "      <th>110</th>\n",
       "      <th>260</th>\n",
       "      <th>296</th>\n",
       "      <th>318</th>\n",
       "      <th>356</th>\n",
       "      <th>480</th>\n",
       "      <th>527</th>\n",
       "      <th>589</th>\n",
       "      <th>593</th>\n",
       "      <th>1196</th>\n",
       "      <th>2571</th>\n",
       "      <th>2959</th>\n",
       "      <th>4993</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7858</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14674</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17035</th>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22744</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49305</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53192</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55653</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57304</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123465</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129705</th>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133878</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171795</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175325</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198515</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1     50    110   260   296   318   356   480   527   589   593   \\\n",
       "userId                                                                      \n",
       "7858      5.0   5.0   3.5   4.5   5.0   5.0   2.0   3.0   5.0   3.5   2.5   \n",
       "10202     5.0   5.0   1.0   5.0   5.0   5.0   4.0   4.0   5.0   4.0   5.0   \n",
       "14674     3.0   4.5   5.0   5.0   2.0   2.5   5.0   2.0   3.5   5.0   3.0   \n",
       "17035     3.5   5.0   4.0   0.5   5.0   5.0   3.5   3.0   4.5   3.5   5.0   \n",
       "22744     5.0   4.0   4.0   5.0   5.0   3.0   4.0   5.0   0.5   5.0   5.0   \n",
       "49305     5.0   4.5   4.0   5.0   5.0   4.5   4.5   4.0   5.0   5.0   5.0   \n",
       "53192     NaN   4.0   3.5   5.0   3.5   4.5   4.0   3.0   4.0   3.0   4.0   \n",
       "55653     4.0   4.5   5.0   4.0   4.5   4.0   4.0   3.0   4.0   4.0   4.0   \n",
       "57304     4.0   3.0   NaN   2.5   4.0   2.5   NaN   2.0   5.0   3.0   4.0   \n",
       "123465    5.0   2.5   2.0   3.5   5.0   5.0   4.0   2.0   4.5   3.0   4.0   \n",
       "129705    4.5   5.0   5.0   4.0   5.0   4.0   4.0   4.5   5.0   4.0   4.0   \n",
       "133878    4.0   3.0   4.0   5.0   5.0   5.0   4.0   2.0   5.0   3.5   3.5   \n",
       "171795    3.0   4.0   4.0   4.0   4.0   4.5   3.0   4.0   4.0   4.0   4.0   \n",
       "175325    4.0   4.0   3.5   4.0   4.5   4.5   3.5   4.0   4.5   4.0   4.0   \n",
       "198515    3.0   4.0   4.0   3.0   4.0   4.0   4.0   4.0   4.0   4.0   4.5   \n",
       "\n",
       "movieId  1196  2571  2959  4993  \n",
       "userId                           \n",
       "7858      5.0   5.0   4.0   5.0  \n",
       "10202     5.0   5.0   5.0   5.0  \n",
       "14674     5.0   4.0   3.5   5.0  \n",
       "17035     0.5   1.5   4.5   3.0  \n",
       "22744     5.0   5.0   5.0   5.0  \n",
       "49305     5.0   5.0   4.0   4.5  \n",
       "53192     4.5   2.5   3.0   3.0  \n",
       "55653     4.0   4.0   3.0   4.0  \n",
       "57304     3.0   4.0   3.5   3.0  \n",
       "123465    4.5   2.0   4.5   5.0  \n",
       "129705    4.5   5.0   5.0   5.0  \n",
       "133878    5.0   5.0   5.0   5.0  \n",
       "171795    4.0   4.5   4.0   4.5  \n",
       "175325    4.0   4.0   3.5   4.0  \n",
       "198515    2.5   4.0   2.0   4.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_preview(ratings, n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b26553de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(ratings, top=None):\n",
    "    if top is not None:\n",
    "        ratings.groupby('userId')['rating'].count()\n",
    "    \n",
    "    unique_users = ratings.userId.unique()\n",
    "    user_to_index = {old: new for new, old in enumerate(unique_users)}\n",
    "    new_users = ratings.userId.map(user_to_index)\n",
    "    \n",
    "    unique_movies = ratings.movieId.unique()\n",
    "    movie_to_index = {old: new for new, old in enumerate(unique_movies)}\n",
    "    new_movies = ratings.movieId.map(movie_to_index)\n",
    "        \n",
    "    n_users = unique_users.shape[0]\n",
    "    n_movies = unique_movies.shape[0]\n",
    "    \n",
    "    X = pd.DataFrame({'user_id': new_users, 'movie_id': new_movies})\n",
    "    y = ratings['rating'].astype(np.float32)\n",
    "    return (n_users, n_movies), (X, y), (user_to_index, movie_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "206548ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: 200948 users, 84432 movies\n",
      "Dataset shape: (32000204, 2)\n",
      "Target shape: (32000204,)\n"
     ]
    }
   ],
   "source": [
    "(n, m), (X, y), (user_to_index, movie_to_index) = create_dataset(ratings)\n",
    "print(f'Embeddings: {n} users, {m} movies')\n",
    "print(f'Dataset shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8010a414",
   "metadata": {},
   "source": [
    "# Creating the Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1209c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewsIterator:\n",
    "    \n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        \n",
    "        if shuffle:\n",
    "            index = np.random.permutation(X.shape[0])\n",
    "            X, y = X[index], y[index]\n",
    "            \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_batches = int(math.ceil(X.shape[0] // batch_size))\n",
    "        self._current = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "    def next(self):\n",
    "        if self._current >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "        k = self._current\n",
    "        self._current += 1\n",
    "        bs = self.batch_size\n",
    "        return self.X[k*bs:(k + 1)*bs], self.y[k*bs:(k + 1)*bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62826ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(X, y, bs=32, shuffle=True):\n",
    "    for xb, yb in ReviewsIterator(X, y, bs, shuffle):\n",
    "        xb = torch.LongTensor(xb)\n",
    "        yb = torch.FloatTensor(yb)\n",
    "        yield xb, yb.view(-1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "369af949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 66953,   5323],\n",
      "        [  9876,   1582],\n",
      "        [ 38347,    968],\n",
      "        [101951,    517]])\n",
      "tensor([[5.],\n",
      "        [4.],\n",
      "        [2.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in batches(X, y, bs=4):\n",
    "    print(x_batch)\n",
    "    print(y_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99f69bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp threshold (80th percentile): 1538551302.0\n",
      "Newer data (for ETL pipeline): 6,400,041 samples\n",
      "Older data (for train/val split): 25,600,163 samples\n",
      "\n",
      "Final split sizes:\n",
      "Training: 20,480,130\n",
      "Validation: 5,120,033\n",
      "Newer (ETL): 6,400,041\n",
      "Total: 32,000,204\n"
     ]
    }
   ],
   "source": [
    "# Time-based split: 20% newest data for ETL pipeline testing\n",
    "timestamp_threshold = ratings['timestamp'].quantile(0.8)\n",
    "print(f\"Timestamp threshold (80th percentile): {timestamp_threshold}\")\n",
    "\n",
    "# Split by timestamp\n",
    "older_data_mask = ratings['timestamp'] <= timestamp_threshold\n",
    "newer_data_mask = ratings['timestamp'] > timestamp_threshold\n",
    "\n",
    "# Get indices for X and y\n",
    "older_indices = X.index[older_data_mask]\n",
    "newer_indices = X.index[newer_data_mask]\n",
    "\n",
    "# Create newer dataset (20% most recent)\n",
    "X_newer = X.loc[newer_indices].reset_index(drop=True)\n",
    "y_newer = y.loc[newer_indices].reset_index(drop=True)\n",
    "\n",
    "# Create older dataset (80% older data)\n",
    "X_older = X.loc[older_indices].reset_index(drop=True)\n",
    "y_older = y.loc[older_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"Newer data (for ETL pipeline): {len(X_newer):,} samples\")\n",
    "print(f\"Older data (for train/val split): {len(X_older):,} samples\")\n",
    "\n",
    "# Now do normal train/test split on the older data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "   X_older, y_older, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Organize datasets\n",
    "datasets = {\n",
    "   'train': (X_train, y_train),\n",
    "   'val': (X_valid, y_valid),\n",
    "   'newer': (X_newer, y_newer)  # For ETL pipeline testing\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "'train': len(X_train),\n",
    "   'val': len(X_valid),\n",
    "   'newer': len(X_newer)\n",
    "}\n",
    "\n",
    "print(f\"\\nFinal split sizes:\")\n",
    "print(f\"Training: {dataset_sizes['train']:,}\")\n",
    "print(f\"Validation: {dataset_sizes['val']:,}\")\n",
    "print(f\"Newer (ETL): {dataset_sizes['newer']:,}\")\n",
    "print(f\"Total: {sum(dataset_sizes.values()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf032d9c",
   "metadata": {},
   "source": [
    "# Export Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9673ec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting datasets with temporal features...\n",
      "Train ratings shape: (20480130, 5)\n",
      "Val ratings shape: (5120033, 5)\n",
      "Test ratings shape: (6400041, 5)\n",
      "Adding temporal features to train data...\n",
      "Adding temporal features to val data...\n",
      "Adding temporal features to test data...\n",
      "✅ Training data exported: 20,480,130 samples\n",
      "✅ Validation data exported: 5,120,033 samples\n",
      "✅ Test data exported: 6,400,041 samples\n",
      "✅ Data mappings saved to data/processed/\n",
      "\n",
      "Final column format: ['userId', 'movieId', 'rating', 'timestamp', 'user_idx', 'movie_idx', 'rating_date', 'rating_year', 'rating_month', 'rating_weekday']\n",
      "All datasets now have consistent temporal features!\n",
      "Users: 200948, Movies: 84432\n"
     ]
    }
   ],
   "source": [
    "# Export ALL datasets with temporal features for training\n",
    "print(\"Exporting datasets with temporal features...\")\n",
    "\n",
    "# We need to get back to the original ratings indices for each split\n",
    "# The issue is X_train.index doesn't correspond to ratings.index after the splits\n",
    "\n",
    "# Get the original indices from the splits\n",
    "train_mask_indices = older_indices[X_train.index]\n",
    "val_mask_indices = older_indices[X_valid.index] \n",
    "test_mask_indices = newer_indices\n",
    "\n",
    "# Create datasets with full temporal information using original ratings data\n",
    "train_ratings = ratings.iloc[train_mask_indices].copy()\n",
    "val_ratings = ratings.iloc[val_mask_indices].copy()\n",
    "test_ratings = ratings.iloc[test_mask_indices].copy()\n",
    "\n",
    "print(f\"Train ratings shape: {train_ratings.shape}\")\n",
    "print(f\"Val ratings shape: {val_ratings.shape}\")  \n",
    "print(f\"Test ratings shape: {test_ratings.shape}\")\n",
    "\n",
    "# Add user/movie indices to all datasets\n",
    "train_ratings['user_idx'] = train_ratings['userId'].map(user_to_index)\n",
    "train_ratings['movie_idx'] = train_ratings['movieId'].map(movie_to_index)\n",
    "\n",
    "val_ratings['user_idx'] = val_ratings['userId'].map(user_to_index)\n",
    "val_ratings['movie_idx'] = val_ratings['movieId'].map(movie_to_index)\n",
    "\n",
    "test_ratings['user_idx'] = test_ratings['userId'].map(user_to_index)\n",
    "test_ratings['movie_idx'] = test_ratings['movieId'].map(movie_to_index)\n",
    "\n",
    "# Add temporal features to all datasets\n",
    "for name, df in [(\"train\", train_ratings), (\"val\", val_ratings), (\"test\", test_ratings)]:\n",
    "    print(f\"Adding temporal features to {name} data...\")\n",
    "    df['rating_date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "    df['rating_year'] = df['rating_date'].dt.year\n",
    "    df['rating_month'] = df['rating_date'].dt.month\n",
    "    df['rating_weekday'] = df['rating_date'].dt.weekday\n",
    "    # Convert to string for CSV compatibility\n",
    "    df['rating_date'] = df['rating_date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Define consistent column order\n",
    "columns = ['userId', 'movieId', 'rating', 'timestamp', 'user_idx', 'movie_idx', \n",
    "           'rating_date', 'rating_year', 'rating_month', 'rating_weekday']\n",
    "\n",
    "# Prepare final datasets\n",
    "train_df = train_ratings[columns].copy()\n",
    "val_df = val_ratings[columns].copy()\n",
    "test_df = test_ratings[columns].copy()\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "# Export to CSV files with temporal features\n",
    "train_df.to_csv('data/processed/train_data.csv', index=False)\n",
    "val_df.to_csv('data/processed/val_data.csv', index=False)\n",
    "test_df.to_csv('data/processed/test_data.csv', index=False)\n",
    "\n",
    "print(f\"✅ Training data exported: {len(train_df):,} samples\")\n",
    "print(f\"✅ Validation data exported: {len(val_df):,} samples\")\n",
    "print(f\"✅ Test data exported: {len(test_df):,} samples\")\n",
    "\n",
    "# Save mappings to processed directory\n",
    "import pickle\n",
    "mappings = {\n",
    "   'user_to_index': user_to_index,\n",
    "   'movie_to_index': movie_to_index,\n",
    "   'n_users': n,\n",
    "   'n_movies': m,\n",
    "   'minmax': minmax\n",
    "}\n",
    "\n",
    "with open('data/processed/data_mappings.pkl', 'wb') as f:\n",
    "    pickle.dump(mappings, f)\n",
    "\n",
    "print(\"✅ Data mappings saved to data/processed/\")\n",
    "print(f\"\\nFinal column format: {list(train_df.columns)}\")\n",
    "print(f\"All datasets now have consistent temporal features!\")\n",
    "print(f\"Users: {n}, Movies: {m}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
